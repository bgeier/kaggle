{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport librosa\nimport librosa.display\n\nimport IPython.display as ipd\n\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"../input\"))\n\nimport torchaudio\nfrom sklearn.decomposition import PCA\n\nimport seaborn as sns\n\nimport time\nimport gc\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom gensim.models import Word2Vec\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Labels = pd.read_csv(\"../input/train_curated.csv\")\nWavPath = \"../input/train_curated/\"\nFils = os.listdir(WavPath)\nsound, sample_rate = torchaudio.load(WavPath+Fils[7])\nipd.Audio(data=sound[0,:],rate=sample_rate) # load a local WAV file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, sr = librosa.load(WavPath+Fils[7])\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_audio_embedding(fname,n_components=10):\n    x, sr = librosa.load(fname)\n    X = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    pca = PCA(n_components=n_components)\n    pca.fit(Xdb.T)\n    return pca.components_.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_Xdb(fname):\n    x, sr = librosa.load(fname)\n    X = librosa.stft(x)\n    Xdb = librosa.amplitude_to_db(abs(X))\n    return Xdb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_overall_lwlrap_sklearn(truth, scores):\n    \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n    # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n    sample_weight = np.sum(truth > 0, axis=1)\n    nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n    overall_lwlrap = label_ranking_average_precision_score(\n        truth[nonzero_weight_sample_indices, :] > 0, \n        scores[nonzero_weight_sample_indices, :], \n        sample_weight=sample_weight[nonzero_weight_sample_indices])\n    return overall_lwlrap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_classes = 80\n\ndef split_and_label(rows_labels, n_classes):\n    '''\n    Retrieves a list of all the relevant classes. This is necessary due to \n    the multi-labeling of the initial csv file.\n    '''\n    row_labels_list = []\n    for row in rows_labels:\n        row_labels = row.split(',')\n        labels_array = np.zeros((n_classes))\n        for label in row_labels:\n            index = label_mapping[label]\n            labels_array[index] = 1\n        row_labels_list.append(labels_array)\n    return row_labels_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load in data\ndf = pd.read_csv('../input/train_curated.csv')\ntest_df = pd.read_csv('../input/sample_submission.csv')\n\n# Retrieve labels\nlabel_columns = test_df.columns[1:]\nlabel_mapping = dict((label, index) for index, label in enumerate(label_columns))\nfor col in label_columns:\n    df[col] = 0  \ndf[label_columns] = split_and_label(df['labels'], n_classes)\ndf['num_labels'] = df[label_columns].sum(axis=1)\nprint(df.head())\n\nprint(test_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nget_audio_embedding(WavPath + Fils[0]).shape\nprint(time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#start = time.time()\n#embeddings = {str(i):get_audio_embedding(WavPath + fname) for (i,fname) in zip(range(len(Fils)), Fils)}\n#print(time.time() - start)\n#gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# basic schema nutshell..\n\nx = pd.DataFrame(index=range(1025))\nstart = time.time()\nfor key in range(len(Fils)):\n    x = x.merge(pd.DataFrame(get_audio_embedding(WavPath + Fils[key]),columns=[Fils[key]+'.'+ str(col) for col in range(10)])\n                ,left_index=True,right_index=True)\n    #x = x.merge(pd.DataFrame(embeddings[str(key)],columns=[Fils[key]+'.'+ str(col) for col in range(10)])\n     #           ,left_index=True,right_index=True)\nprint(time.time() - start)\ngc.collect()\n\ny = pd.DataFrame(get_Xdb(WavPath + Fils[10]))\nsns.heatmap(y)\nprint(x.shape)\nprint(y.shape)\n\nprint(x.corrwith(y[0]))\nprint(np.argmax(x.corrwith(y[0])))\ndef convert_Xdb2token(Xdb, hv):\n    # for every column Xdb, return hv column name with highest correlation\n    cols = hv.columns\n    p,n = Xdb.shape\n    \n    def get_idx(x,hv):\n        return np.argmax(hv.corrwith(x))\n    \n    Xdb = pd.DataFrame(Xdb)\n    \n    final_array = [ get_idx(Xdb[col],hv) for col in Xdb.columns]\n    \n    return final_array\n\nyseq = convert_Xdb2token(y, x)\nprint(yseq)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nyseq = [convert_Xdb2token(pd.DataFrame(get_Xdb(WavPath+Fils[i])),x) for i in range(len(Fils))]\nprint(time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#start = time.time()\n#model = Word2Vec(yseq, size=300, window=5, min_count=1, workers=4)\n#print(time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# develop an embedding relating spectra co-occurence..\n\n# need a lexicon defined in spectral domain..\n\n# find all Hz sequences\n\n# Discover a finite vocabulary\n\n# Tokenize S relative to vocabulary\n\n# Discover embedding given token-to-token co-occurence\n\n# apply keras with embedding layer","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}